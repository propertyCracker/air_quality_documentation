# Model Selection

This section explains how the LLM model is chosen and configured.

## Model Options
- Azure OpenAI (preferred for enterprise use)
- Open-source models (if offline or cost-optimized)
- Smaller models for edge/limited environments

## Selection Strategy
1. Accuracy for environmental question-answering  
2. Latency for real-time responses  
3. Token limits for long data summaries  

